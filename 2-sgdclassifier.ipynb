{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "secret-eugene",
   "metadata": {},
   "source": [
    "# LAB 6: Text classification with linear models\n",
    "\n",
    "Objectives:\n",
    "\n",
    "* Train and evaluate linear text classifiers using SGDClassifier\n",
    "* Experiment with different feature extraction and training methods\n",
    "* Log and evaluate experimental results using [mlflow](https://mlflow.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rising-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-hartford",
   "metadata": {},
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rural-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\n",
    "    \"s3://ling583/rcv1-topics-train.parquet\", storage_options={\"anon\": True}\n",
    ")\n",
    "test = pd.read_parquet(\n",
    "    \"s3://ling583/rcv1-topics-test.parquet\", storage_options={\"anon\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "qualified-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NZ bonds close well bid ahead of key U.S. data...</td>\n",
       "      <td>MCAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asia Product Swaps - Jet/gas oil regrade at di...</td>\n",
       "      <td>MCAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. public schools get a C report card in qua...</td>\n",
       "      <td>GCAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thunder Bay vessel clearances - May 12. Daily ...</td>\n",
       "      <td>MCAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amoco gains shares in Ula,Gyda N.Sea fields. A...</td>\n",
       "      <td>CCAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text topics\n",
       "0  NZ bonds close well bid ahead of key U.S. data...   MCAT\n",
       "1  Asia Product Swaps - Jet/gas oil regrade at di...   MCAT\n",
       "2  U.S. public schools get a C report card in qua...   GCAT\n",
       "3  Thunder Bay vessel clearances - May 12. Daily ...   MCAT\n",
       "4  Amoco gains shares in Ula,Gyda N.Sea fields. A...   CCAT"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-analysis",
   "metadata": {},
   "source": [
    "CCAT : CORPORATE/INDUSTRIAL  \n",
    "ECAT : ECONOMICS  \n",
    "GCAT : GOVERNMENT/SOCIAL  \n",
    "MCAT : MARKETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bizarre-knowing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CCAT    5896\n",
       "MCAT    3281\n",
       "GCAT    3225\n",
       "ECAT    1073\n",
       "Name: topics, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"topics\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extensive-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_sm\",\n",
    "    exclude=[\"tagger\", \"parser\", \"ner\", \"lemmatizer\", \"attribute_ruler\"],\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp.tokenizer(text)\n",
    "    return [t.norm_ for t in doc if t.is_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authentic-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chicken-briefing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1026d09d04945788ac6d98feb85d3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da62c12c5949489086a5eb26c5c678f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mp.Pool() as p:\n",
    "    train[\"tokens\"] = pd.Series(p.imap(tokenize, tqdm(train[\"text\"]), chunksize=100))\n",
    "    test[\"tokens\"] = pd.Series(p.imap(tokenize, tqdm(test[\"text\"]), chunksize=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "irish-junction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topics</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NZ bonds close well bid ahead of key U.S. data...</td>\n",
       "      <td>MCAT</td>\n",
       "      <td>[nz, bonds, close, well, bid, ahead, of, key, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asia Product Swaps - Jet/gas oil regrade at di...</td>\n",
       "      <td>MCAT</td>\n",
       "      <td>[asia, product, swaps, jet, gas, oil, regrade,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. public schools get a C report card in qua...</td>\n",
       "      <td>GCAT</td>\n",
       "      <td>[public, schools, get, a, c, report, card, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thunder Bay vessel clearances - May 12. Daily ...</td>\n",
       "      <td>MCAT</td>\n",
       "      <td>[thunder, bay, vessel, clearances, may, daily,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amoco gains shares in Ula,Gyda N.Sea fields. A...</td>\n",
       "      <td>CCAT</td>\n",
       "      <td>[amoco, gains, shares, in, ula, gyda, fields, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text topics  \\\n",
       "0  NZ bonds close well bid ahead of key U.S. data...   MCAT   \n",
       "1  Asia Product Swaps - Jet/gas oil regrade at di...   MCAT   \n",
       "2  U.S. public schools get a C report card in qua...   GCAT   \n",
       "3  Thunder Bay vessel clearances - May 12. Daily ...   MCAT   \n",
       "4  Amoco gains shares in Ula,Gyda N.Sea fields. A...   CCAT   \n",
       "\n",
       "                                              tokens  \n",
       "0  [nz, bonds, close, well, bid, ahead, of, key, ...  \n",
       "1  [asia, product, swaps, jet, gas, oil, regrade,...  \n",
       "2  [public, schools, get, a, c, report, card, in,...  \n",
       "3  [thunder, bay, vessel, clearances, may, daily,...  \n",
       "4  [amoco, gains, shares, in, ula, gyda, fields, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-rating",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-underwear",
   "metadata": {},
   "source": [
    "### SGDClassifier\n",
    "\n",
    "We will run the basic SGDClassifier first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brief-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collectible-fitness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CCAT       0.96      0.97      0.96      1475\n",
      "        ECAT       0.93      0.86      0.89       268\n",
      "        GCAT       0.96      0.98      0.97       806\n",
      "        MCAT       0.95      0.95      0.95       820\n",
      "\n",
      "    accuracy                           0.96      3369\n",
      "   macro avg       0.95      0.94      0.94      3369\n",
      "weighted avg       0.96      0.96      0.96      3369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(CountVectorizer(analyzer=identity), SGDClassifier())\n",
    "sgd.fit(train[\"tokens\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nuclear-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logger\n",
    "import mlflow\n",
    "from logger import log_search, log_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expected-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6\")\n",
    "log_test(sgd, test[\"topics\"], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-madagascar",
   "metadata": {},
   "source": [
    "At this point, when we run the basic SGD classifier, our f1 improves from 0.922 to 0.944.  We will now adjust the hyperparameters to see if we can approve the model even more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-hygiene",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-young",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "empty-blogger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33595</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.62 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33595' processes=4 threads=4, memory=16.62 GB>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:33595\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "champion-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from scipy.stats.distributions import loguniform, randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "informational-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "matched-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6/sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "affecting-consensus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 s, sys: 437 ms, total: 7.44 s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 10),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-8, 100.0),\n",
    "    },\n",
    "    n_iter=25,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"topics\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "square-stadium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.04 s, sys: 404 ms, total: 7.44 s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 10),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-8, 1e-1),\n",
    "    },\n",
    "    n_iter=25,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"topics\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-outreach",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### 2.3) Optimized SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rolled-cassette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CCAT       0.97      0.96      0.97      1475\n",
      "        ECAT       0.89      0.87      0.88       268\n",
      "        GCAT       0.96      0.97      0.97       806\n",
      "        MCAT       0.95      0.97      0.96       820\n",
      "\n",
      "    accuracy                           0.96      3369\n",
      "   macro avg       0.94      0.94      0.94      3369\n",
      "weighted avg       0.96      0.96      0.96      3369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity, min_df=9, max_df=0.87), SGDClassifier(alpha=1e-2))\n",
    "sgd.fit(train[\"tokens\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "french-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6\")\n",
    "log_test(sgd, test[\"topics\"], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-cutting",
   "metadata": {},
   "source": [
    "#### 2.1) SGDClassifier with Term-Frequency Times Inverse Document-Frequency (tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "north-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "stone-redhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CCAT       0.97      0.97      0.97      1475\n",
      "        ECAT       0.94      0.82      0.88       268\n",
      "        GCAT       0.95      0.98      0.97       806\n",
      "        MCAT       0.96      0.97      0.96       820\n",
      "\n",
      "    accuracy                           0.96      3369\n",
      "   macro avg       0.95      0.93      0.94      3369\n",
      "weighted avg       0.96      0.96      0.96      3369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(CountVectorizer(analyzer=identity), \n",
    "                    TfidfTransformer(), \n",
    "                    SGDClassifier())\n",
    "sgd.fit(train[\"tokens\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "round-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6\")\n",
    "log_test(sgd, test[\"topics\"], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-transfer",
   "metadata": {},
   "source": [
    "#### 2.2) Hyperparameters for SGDClassifier with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "personal-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6/sgd-tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "characteristic-video",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.14 s, sys: 355 ms, total: 7.5 s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 10),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"tfidftransformer__use_idf\": [True, False],\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-8, 100.0),\n",
    "    },\n",
    "    n_iter=25,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"topics\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "august-reset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.14 s, sys: 387 ms, total: 7.52 s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 10),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"tfidftransformer__use_idf\": [True, False],\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-8, 1e-3),\n",
    "    },\n",
    "    n_iter=25,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"topics\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-wheat",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### 2.3) Optimized SGDClassifier/tf-idf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cognitive-banks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CCAT       0.97      0.97      0.97      1475\n",
      "        ECAT       0.94      0.82      0.88       268\n",
      "        GCAT       0.96      0.98      0.97       806\n",
      "        MCAT       0.96      0.97      0.96       820\n",
      "\n",
      "    accuracy                           0.96      3369\n",
      "   macro avg       0.96      0.94      0.94      3369\n",
      "weighted avg       0.96      0.96      0.96      3369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity, min_df=6, max_df=0.80), TfidfTransformer(use_idf=True), SGDClassifier(alpha=1e-4)\n",
    ")\n",
    "sgd.fit(train[\"tokens\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sonic-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6\")\n",
    "log_test(sgd, test[\"topics\"], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-coordinator",
   "metadata": {},
   "source": [
    "#### 3.1) SGDClassifier with truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "forbidden-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "least-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CCAT       0.96      0.95      0.96      1475\n",
      "        ECAT       0.93      0.70      0.80       268\n",
      "        GCAT       0.92      0.98      0.95       806\n",
      "        MCAT       0.93      0.96      0.94       820\n",
      "\n",
      "    accuracy                           0.94      3369\n",
      "   macro avg       0.93      0.90      0.91      3369\n",
      "weighted avg       0.94      0.94      0.94      3369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(CountVectorizer(analyzer=identity), TfidfTransformer(), TruncatedSVD(n_components=100), SGDClassifier())\n",
    "sgd.fit(train[\"tokens\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caring-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6\")\n",
    "log_test(sgd, test[\"topics\"], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-blair",
   "metadata": {},
   "source": [
    "#### 3.2) Hyperparameters for SGDClassifier with TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "located-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6/sgd-tsvd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "peripheral-toner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.68 s, sys: 530 ms, total: 8.21 s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 10),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"tfidftransformer__use_idf\": [True, False],\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-8, 100.0),\n",
    "    },\n",
    "    n_iter=25,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"topics\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "satisfied-canadian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.76 s, sys: 583 ms, total: 8.35 s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 10),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"tfidftransformer__use_idf\": [True],\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-8, 1e-3),\n",
    "    },\n",
    "    n_iter=25,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"topics\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-disclaimer",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### 3.3) Optimized SGDClassifier/T-SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "described-thomas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CCAT       0.96      0.95      0.96      1475\n",
      "        ECAT       0.90      0.81      0.85       268\n",
      "        GCAT       0.91      0.98      0.95       806\n",
      "        MCAT       0.95      0.94      0.95       820\n",
      "\n",
      "    accuracy                           0.94      3369\n",
      "   macro avg       0.93      0.92      0.92      3369\n",
      "weighted avg       0.94      0.94      0.94      3369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity, min_df=2, max_df=0.55),\n",
    "    TfidfTransformer(use_idf=True), TruncatedSVD(n_components=100), SGDClassifier(alpha=1e-5))\n",
    "sgd.fit(train[\"tokens\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "incorporate-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6\")\n",
    "log_test(sgd, test[\"topics\"], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-latin",
   "metadata": {},
   "source": [
    "#### 4.1) SGDClassifier with unigram/bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "integral-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "def unibigrams(toks):\n",
    "    return [(tok,) for tok in toks] + list(bigrams(toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caroline-spectrum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CCAT       0.97      0.96      0.96      1475\n",
      "        ECAT       0.91      0.85      0.88       268\n",
      "        GCAT       0.95      0.98      0.96       806\n",
      "        MCAT       0.94      0.96      0.95       820\n",
      "\n",
      "    accuracy                           0.95      3369\n",
      "   macro avg       0.94      0.94      0.94      3369\n",
      "weighted avg       0.95      0.95      0.95      3369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(CountVectorizer(analyzer=unibigrams), SGDClassifier())\n",
    "sgd.fit(train[\"tokens\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "subjective-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6\")\n",
    "log_test(sgd, test[\"topics\"], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-episode",
   "metadata": {},
   "source": [
    "#### 4.2) Hyperparameters for SGDClassifier with unigram/bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sapphire-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6/sgd-ug-bg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "common-programmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 3.24 s, total: 1min 13s\n",
      "Wall time: 7min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 10),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-8, 100.0),\n",
    "    },\n",
    "    n_iter=25,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"topics\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "amber-rainbow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 3.41 s, total: 1min 14s\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 10),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-8, 1e-3),\n",
    "    },\n",
    "    n_iter=25,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"topics\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-proxy",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### 4.3) Optimized SGDClassifier with Unigram/Bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "vital-portugal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CCAT       0.97      0.97      0.97      1475\n",
      "        ECAT       0.91      0.86      0.88       268\n",
      "        GCAT       0.96      0.98      0.97       806\n",
      "        MCAT       0.96      0.96      0.96       820\n",
      "\n",
      "    accuracy                           0.96      3369\n",
      "   macro avg       0.95      0.94      0.95      3369\n",
      "weighted avg       0.96      0.96      0.96      3369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=unibigrams, min_df=2, max_df=0.57), SGDClassifier(alpha=1e-3))\n",
    "sgd.fit(train[\"tokens\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "european-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-6\")\n",
    "log_test(sgd, test[\"topics\"], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-encounter",
   "metadata": {},
   "source": [
    "### Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-porter",
   "metadata": {},
   "source": [
    "* MNB Classifier = 0.944\n",
    "* MNB Classifier Optimized = 0.915\n",
    "* SGD Classifier F1 Score = 0.945\n",
    "* SGD Classifier Optimized F1 Score = 0.943\n",
    "* SGD Classifier with tf-idf F1 Score = 0.943\n",
    "* SGD Classifier with tf-idf Optimized F1 Score = 0.945\n",
    "* SGD Classifier with truncated SVD F1 Score = 0.912\n",
    "* SGD Classifier with truncated SVD Optimized F1 Score = 0.925\n",
    "* SGD Classifier with unigram/bigram F1 Score = 0.94\n",
    "* SGD Classifier with unigram/bigram Optimized F1 Score = 0.946\n",
    "\n",
    "Out of all the  F1 scores, the SGD Classifier with unigram/bigram optimized came in 1st with the highest F1 score of 0.946, but both the SGD Classifier baseline and SGD Classifier with tf-idf optimized had the 2nd highest F1 score of 0.945.  The third highest F1 score came from the SGD Classifier with unigram/bigram baseline at 0.94.  These 4 are the best, but because they are so close, I would use all 4 and monitor them over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-prompt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
